{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip3 install pandas numpy scikit-learn lightgbm matplotlib duckdb pyarrow\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "import duckdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, auc, roc_curve, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score, \n",
    "                             precision_recall_curve, roc_auc_score, brier_score_loss)\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "# install pyarrow to work with parquet files\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "random.seed(37)\n",
    "np.random.seed(37)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control panel- User Input required\n",
    "\n",
    "Update root location, input filetype, site_name and confirm that race/ethnicity mapping correct. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 34,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the location for your CLIF-1.0 directory\n",
<<<<<<< HEAD
    "root_location = 'C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main'\n",
    "# either parquet or csv only\n",
    "filetype = 'csv'\n",
    "site_name='RUSH'\n",
=======
    "root_location = '/Users/kavenchhikara/Desktop/CLIF-1.0'\n",
    "# either parquet or csv only\n",
    "filetype = 'parquet'\n",
    "site_name='UCMC'\n",
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
    "\n",
    "race_map = {\n",
    "    'White': 'White',\n",
    "    'Black or African American': 'Black',\n",
    "    ## added\n",
    "    'Black or African-American' : 'Black',\n",
    "    'Asian': 'Asian',\n",
    "    'Other': 'Others',\n",
    "    'Unknown': 'Others',\n",
    "    'Did Not Encounter': 'Others',\n",
    "    'Refusal': 'Others',\n",
    "    'American Indian or Alaska Native': 'Others',\n",
    "    'Native Hawaiian or Other Pacific Islander': 'Others',\n",
    "    np.nan: 'Others'\n",
    "}\n",
    "\n",
    "ethnicity_map = {\n",
    "    'Not Hispanic': 'Not Hispanic or Latino',\n",
    "    'Hispanic': 'Hispanic or Latino',\n",
    "    'Unknown': 'Others',\n",
    "    # 'Refusal': 'Others',\n",
    "    '*Unspecified': 'Others',\n",
    "    np.nan: 'Others'\n",
    "}\n",
    "\n",
    "finetune=True"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 35,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "adt_filepath = f\"{root_location}/rclif/clif_adt.{filetype}\"\n",
    "encounter_filepath = f\"{root_location}/rclif/clif_encounter_demographics_dispo.{filetype}\"\n",
    "limited_filepath = f\"{root_location}/rclif/clif_limited_identifiers.{filetype}\"\n",
    "demog_filepath = f\"{root_location}/rclif/clif_patient_demographics.{filetype}\"\n",
    "vitals_filepath = f\"{root_location}/rclif/clif_vitals.{filetype}\"\n",
    "labs_filepath = f\"{root_location}/rclif/clif_labs.{filetype}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 43,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, filetype):\n",
    "    \"\"\"\n",
    "    Read data from file based on file type.\n",
    "    Parameters:\n",
    "        filepath (str): Path to the file.\n",
    "        filetype (str): Type of the file ('csv' or 'parquet').\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    if filetype == 'csv':\n",
    "        return pd.read_csv(filepath)\n",
    "    elif filetype == 'parquet':\n",
    "        table = pq.read_table(filepath)\n",
    "        return table.to_pandas()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please provide either 'csv' or 'parquet'.\")\n",
    "    \n",
    "\n",
    "def standardize_datetime(df):\n",
    "    \"\"\"\n",
    "    Ensure that all *_dttm variables are in the correct format.\n",
    "    Convert all datetime columns to a specific precision and remove timezone\n",
    "    Parameters:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Here converting to 'datetime64[ns]' for uniformity and removing timezone with 'tz_convert(None)'\n",
    "            df[col] = df[col].dt.tz_convert(None) if df[col].dt.tz is not None else df[col]\n",
    "            # If you need to standardize to UTC and keep the timezone:\n",
    "            # df[col] = df[col].dt.tz_localize('UTC') if df[col].dt.tz is None else df[col].dt.tz_convert('UTC')\n",
    "    return df\n",
    "\n",
    "def get_sql_import(filetype):\n",
    "    if filetype == 'parquet':\n",
    "        return 'read_parquet'\n",
    "    if filetype == 'csv':\n",
    "        return 'read_csv_auto'\n",
    "\n",
    "sql_import = get_sql_import(filetype=filetype)\n",
    "\n",
    "# create output directory\n",
    "output_directory = os.path.join(os.getcwd(), 'output')\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 40,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "location = read_data(adt_filepath, filetype)\n",
    "encounter = read_data(encounter_filepath, filetype)\n",
    "limited = read_data(limited_filepath, filetype)\n",
    "demog = read_data(demog_filepath, filetype)\n",
    "\n",
    "# Apply the standardization function to each DataFrame\n",
    "location = standardize_datetime(location)\n",
    "encounter = standardize_datetime(encounter)\n",
    "limited = standardize_datetime(limited)\n",
    "demog = standardize_datetime(demog)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU close to Admission\n",
    "\n",
    "1. Check ICU location_category between admission_dttmtime and 48hr stop from admission\n",
    "2. Check ICU stay at least 24 hr (for ICU - OR - ICU including OR in ICU stay 24hr)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 41,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "join=pd.merge(location[['encounter_id','location_category','in_dttm','out_dttm']],\\\n",
    "              limited[['encounter_id','admission_dttm']], on=['encounter_id'], how='left')\n",
    "\n",
    "icu_data=pd.merge(join,\\\n",
    "                  encounter[['encounter_id','age_at_admission','disposition']], on=['encounter_id'], how='left')\n",
    "\n",
    "\n",
    "icu_data['in_dttm'] = pd.to_datetime(icu_data['in_dttm'])\n",
    "icu_data['admission_dttm'] = pd.to_datetime(icu_data['admission_dttm'])\n",
    "icu_data['out_dttm'] = pd.to_datetime(icu_data['out_dttm'])\n",
<<<<<<< HEAD
    "icu_data['age_at_admission'] = icu_data['age_at_admission'].astype(int)\n",
=======
    "icu_data['age_at_admission'] = icu_data['age_at_admission'].fillna(-1)\n",
    "icu_data['age_at_admission'] = icu_data['age_at_admission'].astype(int)\n",
    "# Select people over 18 with non-null ages\n",
    "icu_data= icu_data[(icu_data['age_at_admission'] > 18) & (icu_data['age_at_admission'] != -1)].reset_index(drop=True)\n",
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
    "\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) &\n",
    "    (icu_data['in_dttm'].dt.year >= 2020) & (icu_data['in_dttm'].dt.year <= 2022) & \n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())\n",
    "]['encounter_id'].unique()\n",
    "\n",
    "icu_data=icu_data[icu_data['encounter_id'].isin(icu_48hr_check) & (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))].reset_index(drop=True)\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "\n",
    "icu_data[\"RANK\"]=icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"encounter_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n",
    "\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['RANK'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "icu_data=icu_data[icu_data['RANK']>=icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "icu_data['group_id'] = (icu_data.groupby('encounter_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('encounter_id')['group_id'].cumsum()\n",
    "\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['encounter_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('disposition', 'first')\n",
    ").reset_index()\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['group_id'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "\n",
    "icu_data=icu_data[(icu_data['min_icu']==icu_data['group_id']) &\n",
    "         (icu_data['max_out_dttm']-icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "         ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "icu_data['after_24hr']=icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "icu_data=icu_data[['encounter_id','min_in_dttm','after_24hr','age','dispo']]\n",
    "\n",
    "icu_data=pd.merge(icu_data,\\\n",
    "                  demog, on=['encounter_id'], how='left')[['encounter_id','min_in_dttm','after_24hr','age','dispo','sex','ethnicity','race']]\n",
    "icu_data=icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "icu_data['isfemale']=(icu_data['sex'].str.lower() == 'female').astype(int)\n",
    "icu_data['isdeathdispo'] = (icu_data['dispo'].str.contains('dead|expired', case=False, regex=True)).astype(int)\n",
    "\n",
    "icu_data['ethnicity'] = icu_data['ethnicity'].map(ethnicity_map)\n",
    "icu_data['race'] = icu_data['race'].map(race_map)\n",
    "\n",
    "\n",
    "del location,encounter,limited,demog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 44,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = con.execute(f'''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(recorded_dttm AS datetime) AS recorded_dttm,\n",
    "        CAST(vital_value AS float) AS vital_value,\n",
    "        vital_category \n",
    "    FROM \n",
    "        {sql_import}('{vitals_filepath}')\n",
    "    WHERE \n",
    "        vital_category IN ('weight_kg', 'pulse', 'sbp', 'dbp', 'temp_c','height_inches') \n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "vitals=con.execute('''\n",
    "PIVOT vitals\n",
    "ON vital_category\n",
    "USING first(vital_value)\n",
    "GROUP BY encounter_id,recorded_dttm;\n",
    "''').df()\n",
    "\n",
    "vitals['height_meters'] = vitals['height_inches'] * 0.0254\n",
    "\n",
    "# Calculate BMI\n",
    "vitals['bmi'] = vitals['weight_kg'] / (vitals['height_meters'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,vitals, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['recorded_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['recorded_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby(['encounter_id']).agg(\n",
    "    min_bmi=('bmi', 'min'),\n",
    "    max_bmi=('bmi', 'max'),\n",
    "    avg_bmi=('bmi', 'mean'),\n",
    "    min_weight_kg=('weight_kg', 'min'),\n",
    "    max_weight_kg=('weight_kg', 'max'),\n",
    "    avg_weight_kg=('weight_kg', 'mean'),\n",
    "    min_pulse=('heart_rate', 'min'),\n",
    "    max_pulse=('heart_rate', 'max'),\n",
    "    avg_pulse=('heart_rate', 'mean'),\n",
    "    min_sbp=('sbp', 'min'),\n",
    "    max_sbp=('sbp', 'max'),\n",
    "    avg_sbp=('sbp', 'mean'),\n",
    "    min_dbp=('dbp', 'min'),\n",
    "    max_dbp=('dbp', 'max'),\n",
    "    avg_dbp=('dbp', 'mean'),\n",
    "    min_temp_c=('temp_c', 'min'),\n",
    "    max_temp_c=('temp_c', 'max'),\n",
    "    avg_temp_c=('temp_c', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')\n",
    "\n",
    "del vitals,icu_data_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = con.execute(f'''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(lab_order_dttm AS datetime) AS lab_order_dttm,\n",
    "        TRY_CAST(lab_value AS float) AS lab_value,\n",
    "        lab_category\n",
    "    FROM \n",
    "         {sql_import}('{labs_filepath}')\n",
    "    WHERE \n",
    "        ((lab_category='monocyte'               and lab_type_name='standard') OR\n",
    "        (lab_category='lymphocyte'              and lab_type_name='standard') OR\n",
    "        (lab_category='basophil'                and lab_type_name='standard') OR\n",
    "        (lab_category='neutrophil'              and lab_type_name='standard') OR\n",
    "        (lab_category='albumin'                 and lab_type_name='standard') OR\n",
    "        (lab_category='ast'                     and lab_type_name='standard') OR\n",
    "        (lab_category='total_protein'           and lab_type_name='standard') OR\n",
    "        (lab_category='alkaline_phosphatase'    and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_total'         and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_conjugated'    and lab_type_name='standard') OR\n",
    "        (lab_category='calcium'                 and lab_type_name='standard') OR\n",
    "        (lab_category='chloride'                and lab_type_name='standard') OR\n",
    "        (lab_category='potassium'               and lab_type_name='standard') OR\n",
    "        (lab_category='sodium'                  and lab_type_name='standard') OR\n",
    "        (lab_category='glucose_serum'           and lab_type_name='standard') OR\n",
    "        (lab_category='hemoglobin'              and lab_type_name='standard') OR\n",
    "        (lab_category='platelet count'          and lab_type_name='standard') OR\n",
    "        (lab_category='wbc'                     and lab_type_name='standard'))  \n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "labs=con.execute('''\n",
    "PIVOT labs\n",
    "ON lab_category\n",
    "USING first(lab_value)\n",
    "GROUP BY encounter_id,lab_order_dttm;\n",
    "''').df()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,labs, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['lab_order_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['lab_order_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "icu_data_agg['sodium'] = np.NaN \n",
    "icu_data_agg['glucose_serum'] = np.NaN \n",
    "icu_data_agg['total_protein'] = np.NaN \n",
    "icu_data_agg['platelet count'] = np.NaN \n",
    "\n",
    "\n",
    "Lab_variables = [\n",
    "   'albumin', 'alkaline_phosphatase',\n",
    "       'ast', 'basophil', 'bilirubin_conjugated', 'bilirubin_total', 'calcium',\n",
    "       'chloride', 'hemoglobin', 'lymphocyte', 'monocyte', 'glucose_serum', \n",
    "       'neutrophil', 'potassium', 'sodium', 'total_protein','platelet count', \n",
    "       'wbc'\n",
    "]\n",
    "agg_dict = {var: ['min', 'max', 'mean'] for var in Lab_variables}\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby('encounter_id').agg(agg_dict).reset_index()\n",
    "\n",
    "icu_data_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in icu_data_agg.columns.values]\n",
<<<<<<< HEAD
    "\n",
=======
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "model_col=['isfemale','age', 'min_bmi', 'max_bmi', 'avg_bmi',\n",
    "       'min_weight_kg', 'max_weight_kg', 'avg_weight_kg', 'min_pulse',\n",
    "       'max_pulse', 'avg_pulse', 'min_sbp', 'max_sbp', 'avg_sbp', 'min_dbp',\n",
    "       'max_dbp', 'avg_dbp', 'min_temp_c', 'max_temp_c', 'avg_temp_c',\n",
    "       'albumin_min', 'albumin_max', 'albumin_mean',\n",
    "       'alkaline_phosphatase_min', 'alkaline_phosphatase_max',\n",
    "       'alkaline_phosphatase_mean', 'ast_min', 'ast_max', 'ast_mean',\n",
    "       'basophil_min', 'basophil_max', 'basophil_mean',\n",
    "       'bilirubin_conjugated_min', 'bilirubin_conjugated_max',\n",
    "       'bilirubin_conjugated_mean', 'bilirubin_total_min',\n",
    "       'bilirubin_total_max', 'bilirubin_total_mean', 'calcium_min',\n",
    "       'calcium_max', 'calcium_mean', 'chloride_min', 'chloride_max',\n",
    "       'chloride_mean', \n",
    "       'hemoglobin_min', 'hemoglobin_max',\n",
    "       'hemoglobin_mean', 'lymphocyte_min', 'lymphocyte_max',\n",
    "       'lymphocyte_mean', 'monocyte_min', 'monocyte_max', 'monocyte_mean',\n",
    "       'neutrophil_min', 'neutrophil_max', 'neutrophil_mean',\n",
    "       'potassium_min', 'potassium_max', 'potassium_mean',\n",
    "       'wbc_min', 'wbc_max', 'wbc_mean',\n",
    "       'platelet count_min', 'platelet count_max', 'platelet count_mean',\n",
    "       'glucose_serum_min', 'glucose_serum_max','glucose_serum_mean', \n",
    "       'sodium_min', 'sodium_max', 'sodium_mean', \n",
    "       'total_protein_min', 'total_protein_max','total_protein_mean',\n",
    "        ]\n",
    "\n",
<<<<<<< HEAD
    "model=lgb.Booster(model_file=f'{root_location}/projects/Mortality_model/models/lgbm_model_20240429-083130.txt')"
=======
    "\n",
    "model=lgb.Booster(model_file=f'{root_location}/projects/Mortality_model/models/lgbm_model_20240425-112249.txt')"
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=icu_data[model_col]\n",
    "y_test=icu_data['isdeathdispo']\n",
    "\n",
    "y_pred_proba = model.predict(X_test)\n",
    "icu_data['pred_proba'] = y_pred_proba\n",
    "# Calculate metrics at default threshold (0.5)\n",
    "\n",
    "accuracy = accuracy_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "recall = recall_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "precision = precision_score(y_test, (y_pred_proba >= 0.5).astype(int))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "results_Metric = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'ROC AUC', 'Brier Score Loss'],\n",
    "    'Value': [accuracy, recall, precision, roc_auc, brier_score],\n",
    "    'SiteName': [f'{site_name}'] * 5\n",
    "})\n",
    "\n",
    "results_Metric.to_csv(f'{output_directory}/result_metrics_{site_name}.csv',index=False)\n",
    "results_Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### probablity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df_lgbm = pd.DataFrame({'site_label ':y_test, 'site_proba': y_pred_proba,'Site_name':f\"{site_name}\" })\n",
    "prob_df_lgbm.to_csv(f'{output_directory}/Model_probabilities_{site_name}.csv',index=False)\n",
    "prob_df_lgbm.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model fairness test accross 'race', 'ethnicity', 'sex'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 21,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data, true_col, pred_prob_col, subgroup_cols):\n",
    "    results = []\n",
    "    total_count = len(data)\n",
    "\n",
    "    for subgroup_col in subgroup_cols:\n",
    "       \n",
    "        filtered_data = data.dropna(subset=[subgroup_col])\n",
    "        \n",
    "        for group in filtered_data[subgroup_col].unique():\n",
    "            subgroup_data = filtered_data[filtered_data[subgroup_col] == group]\n",
    "            group_count = len(subgroup_data)\n",
    "            proportion = group_count / total_count\n",
    "\n",
    "            if np.unique(subgroup_data[true_col]).size > 1:  # Check if both classes are present\n",
    "                auc = roc_auc_score(subgroup_data[true_col], subgroup_data[pred_prob_col])\n",
    "                tn, fp, fn, tp = confusion_matrix(subgroup_data[true_col], (subgroup_data[pred_prob_col] > 0.5).astype(int)).ravel()\n",
    "                ppv = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "                result = {'Subgroup': subgroup_col, 'Group': group, 'AUC': auc, 'PPV': ppv, 'Group Count': group_count, 'Total Count': total_count, 'Proportion': proportion, 'site_name':f'{site_name}'}\n",
    "            else:\n",
    "                result = {'Subgroup': subgroup_col, 'Group': group, 'AUC': 'Not defined', 'PPV': 'Not applicable', 'Group Count': group_count, 'Total Count': total_count, 'Proportion': proportion, 'site_name':f'{site_name}'}\n",
    "            \n",
    "            results.append(result)\n",
    "    \n",
    "   \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "result_df = calculate_metrics(icu_data, 'isdeathdispo', 'pred_proba', ['race', 'ethnicity', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{output_directory}/fairness_test_{site_name}.csv',index=False)\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### thrshold check at site"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_percentile(target_var, pred_proba):\n",
    "    #thr_list = [0.99,0.97, 0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10]\n",
    "    thr_list = np.arange(1, 0, -0.01)\n",
    "    col = ['N Percentile', 'Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "    result = pd.DataFrame(columns = col)\n",
    "    i = 0\n",
    "    \n",
    "    for thr in thr_list: \n",
    "        prob = pd.DataFrame()\n",
    "        prob['target_var'] = target_var\n",
    "        prob['pred_proba'] = pred_proba\n",
    "\n",
    "        thr_value = prob['pred_proba'].quantile(thr)\n",
    "        prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr_value, 1, 0)\n",
    "        tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        ppv = tp/(tp+fp)\n",
    "        npv = tn/(tn+fn)\n",
    "        recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "        n_prec = 'Top '+ str(np.round((1 - thr) * 100,0))+ \"%\"\n",
    "        result.loc[i] = [n_prec,thr_value,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "        i+=1\n",
    "    return result\n",
    "topn=top_n_percentile(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn.to_csv(f'{output_directory}/Top_N_percentile_PPV_{site_name}.csv',index=False)\n",
    "topn.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if finetune:\n",
    "    train_data, test_data = train_test_split(icu_data, test_size=0.5, random_state=42)\n",
    "    X_train=train_data[model_col]\n",
    "    y_train=train_data['isdeathdispo']\n",
    "\n",
    "    #test\n",
    "    X_test=test_data[model_col]\n",
    "    y_test=test_data['isdeathdispo']\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\":-1}\n",
<<<<<<< HEAD
    "    gbm = lgb.train(params, lgb_train, num_boost_round=10, init_model=f'{root_location}/projects/Mortality_model/models/lgbm_model_20240429-083130.txt')\n",
=======
    "    gbm = lgb.train(params, lgb_train, num_boost_round=10, init_model=f'{root_location}/projects/Mortality_model/models/lgbm_model_20240425-112249.txt')\n",
>>>>>>> c331713ccf9ff23444f3ffd0f5ae3e7f6ae7bcb4
    "\n",
    "    y_pred_proba_ft = gbm.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, (y_pred_proba_ft >= 0.5).astype(int))\n",
    "    recall = recall_score(y_test, (y_pred_proba_ft >= 0.5).astype(int))\n",
    "    precision = precision_score(y_test, (y_pred_proba_ft >= 0.5).astype(int))\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba_ft)\n",
    "    brier_score = brier_score_loss(y_test, y_pred_proba_ft)\n",
    "\n",
    "\n",
    "    results_Metric = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Recall', 'Precision', 'ROC AUC', 'Brier Score Loss'],\n",
    "        'Value': [accuracy, recall, precision, roc_auc, brier_score],\n",
    "        'SiteName': [f'{site_name}'] * 5,\n",
    "        'FineTune': ['Yes'] * 5,\n",
    "    })\n",
    "    results_Metric.to_csv(f'{output_directory}/result_metrics_{site_name}_ft.csv',index=False)\n",
    "\n",
    "\n",
    "    model_filename = f\"{output_directory}/lgbm_model_{site_name}_ft.txt\"\n",
    "\n",
    "    # Save the model using LightGBM's built-in function\n",
    "    model.save_model(model_filename)\n",
    "\n",
    "    print(results_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mortality_model)",
   "language": "python",
   "name": ".mortality_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
