{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip3 install pandas numpy scikit-learn lightgbm matplotlib duckdb pyarrow seaborn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "import duckdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, auc, roc_curve, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score, \n",
    "                             precision_recall_curve, roc_auc_score, brier_score_loss)\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "# install pyarrow to work with parquet files\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "random.seed(37)\n",
    "np.random.seed(37)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control panel- User Input required\n",
    "\n",
    "Update root location, input filetype, site_name and confirm that race/ethnicity mapping correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the location for your CLIF-1.0 directory\n",
    "root_location = 'C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main'\n",
    "# either parquet or csv only\n",
    "filetype = 'csv'\n",
    "site_name='RUSH'\n",
    "\n",
    "race_map = {\n",
    "    'White': 'White',\n",
    "    'Black or African American': 'Black',\n",
    "    'Asian': 'Asian',\n",
    "    'Other': 'Others',\n",
    "    'Unknown': 'Others',\n",
    "    'Did Not Encounter': 'Others',\n",
    "    'Refusal': 'Others',\n",
    "    'American Indian or Alaska Native': 'Others',\n",
    "    'Native Hawaiian or Other Pacific Islander': 'Others',\n",
    "    np.nan: 'Others'\n",
    "}\n",
    "\n",
    "ethnicity_map = {\n",
    "    'Not Hispanic or Latino': 'Not Hispanic or Latino',\n",
    "    'Hispanic or Latino': 'Hispanic or Latino',\n",
    "    'Did Not Encounter': 'Not Hispanic or Latino',\n",
    "    'Refusal': 'Not Hispanic or Latino',\n",
    "    '*Unspecified': 'Not Hispanic or Latino',\n",
    "    np.nan: 'Not Hispanic or Latino'\n",
    "}\n",
    "\n",
    "finetune=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt_filepath = f\"{root_location}/rclif/clif_adt.{filetype}\"\n",
    "encounter_filepath = f\"{root_location}/rclif/clif_encounter_demographics_dispo_clean.{filetype}\"\n",
    "limited_filepath = f\"{root_location}/rclif/clif_limited_identifiers.{filetype}\"\n",
    "demog_filepath = f\"{root_location}/rclif/clif_patient_demographics.{filetype}\"\n",
    "vitals_filepath = f\"{root_location}/rclif/clif_vitals_clean.{filetype}\"\n",
    "labs_filepath = f\"{root_location}/rclif/clif_labs_clean.{filetype}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, filetype):\n",
    "    \"\"\"\n",
    "    Read data from file based on file type.\n",
    "    Parameters:\n",
    "        filepath (str): Path to the file.\n",
    "        filetype (str): Type of the file ('csv' or 'parquet').\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    if filetype == 'csv':\n",
    "        return pd.read_csv(filepath)\n",
    "    elif filetype == 'parquet':\n",
    "        table = pq.read_table(filepath)\n",
    "        return table.to_pandas()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please provide either 'csv' or 'parquet'.\")\n",
    "    \n",
    "\n",
    "def generate_facetgrid_histograms(data, category_column, value_column):\n",
    "    \"\"\"\n",
    "    Generate histograms using seaborn's FacetGrid.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): DataFrame containing the data.\n",
    "        category_column (str): Name of the column containing categories.\n",
    "        value_column (str): Name of the column containing values.\n",
    "\n",
    "    Returns:\n",
    "        FacetGrid: Seaborn FacetGrid object containing the generated histograms.\n",
    "    \"\"\"\n",
    "    # Create a FacetGrid\n",
    "    g = sns.FacetGrid(data, col=category_column, col_wrap=6, sharex=False, sharey=False)\n",
    "    g.map(sns.histplot, value_column, bins=30, color='blue', edgecolor='black')\n",
    "\n",
    "    # Set titles and labels\n",
    "    g.set_titles('{col_name}')\n",
    "    g.set_axis_labels(value_column, 'Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(f'Histograms of {value_column} by {category_column}', fontsize=16)\n",
    "\n",
    "    return g\n",
    "\n",
    "def standardize_datetime(df):\n",
    "    \"\"\"\n",
    "    Ensure that all *_dttm variables are in the correct format.\n",
    "    Convert all datetime columns to a specific precision and remove timezone\n",
    "    Parameters:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Here converting to 'datetime64[ns]' for uniformity and removing timezone with 'tz_convert(None)'\n",
    "            df[col] = df[col].dt.tz_convert(None) if df[col].dt.tz is not None else df[col]\n",
    "            # If you need to standardize to UTC and keep the timezone:\n",
    "            # df[col] = df[col].dt.tz_localize('UTC') if df[col].dt.tz is None else df[col].dt.tz_convert('UTC')\n",
    "    return df\n",
    "\n",
    "def get_sql_import(filetype):\n",
    "    if filetype == 'parquet':\n",
    "        return 'read_parquet'\n",
    "    if filetype == 'csv':\n",
    "        return 'read_csv_auto'\n",
    "\n",
    "sql_import = get_sql_import(filetype=filetype)\n",
    "\n",
    "# create output directory\n",
    "output_directory = os.path.join(os.getcwd(), 'output')\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = read_data(adt_filepath, filetype)\n",
    "encounter = read_data(encounter_filepath, filetype)\n",
    "limited = read_data(limited_filepath, filetype)\n",
    "demog = read_data(demog_filepath, filetype)\n",
    "\n",
    "# Apply the standardization function to each DataFrame\n",
    "location = standardize_datetime(location)\n",
    "encounter = standardize_datetime(encounter)\n",
    "limited = standardize_datetime(limited)\n",
    "demog = standardize_datetime(demog)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU close to Admission\n",
    "\n",
    "1. Check ICU location_category between admission_dttmtime and 48hr stop from admission\n",
    "2. Check ICU stay at least 24 hr (for ICU - OR - ICU including OR in ICU stay 24hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join=pd.merge(location[['encounter_id','location_category','in_dttm','out_dttm']],\\\n",
    "              limited[['encounter_id','admission_dttm']], on=['encounter_id'], how='left')\n",
    "\n",
    "icu_data=pd.merge(join,\\\n",
    "                  encounter[['encounter_id','age_at_admission','disposition']], on=['encounter_id'], how='left')\n",
    "\n",
    "\n",
    "icu_data['in_dttm'] = pd.to_datetime(icu_data['in_dttm'])\n",
    "icu_data['admission_dttm'] = pd.to_datetime(icu_data['admission_dttm'])\n",
    "icu_data['out_dttm'] = pd.to_datetime(icu_data['out_dttm'])\n",
    "#icu_data['age_at_admission'] = icu_data['age_at_admission'].astype(int)\n",
    "\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) &\n",
    "    (icu_data['admission_dttm'].dt.year >= 2020) & (icu_data['admission_dttm'].dt.year <= 2021) & \n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())\n",
    "]['encounter_id'].unique()\n",
    "\n",
    "icu_data=icu_data[icu_data['encounter_id'].isin(icu_48hr_check) & (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))].reset_index(drop=True)\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "\n",
    "icu_data[\"RANK\"]=icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"encounter_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n",
    "\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['RANK'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "icu_data=icu_data[icu_data['RANK']>=icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "icu_data['group_id'] = (icu_data.groupby('encounter_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('encounter_id')['group_id'].cumsum()\n",
    "\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['encounter_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('disposition', 'first')\n",
    ").reset_index()\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['group_id'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "\n",
    "icu_data=icu_data[(icu_data['min_icu']==icu_data['group_id']) &\n",
    "         (icu_data['max_out_dttm']-icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "         ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "icu_data['after_24hr']=icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "icu_data=icu_data[['encounter_id','min_in_dttm','max_out_dttm','after_24hr','age','dispo']]\n",
    "\n",
    "icu_data=pd.merge(icu_data,\\\n",
    "                  demog, on=['encounter_id'], how='left')[['encounter_id','min_in_dttm','after_24hr','max_out_dttm','age','dispo','sex','ethnicity','race']]\n",
    "icu_data=icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "icu_data['isfemale']=(icu_data['sex'].str.lower() == 'female').astype(int)\n",
    "icu_data['isdeathdispo'] = (icu_data['dispo'].str.contains('dead|expired|death|died', case=False, regex=True)).astype(int)\n",
    "\n",
    "icu_data['ethnicity'] = icu_data['ethnicity'].map(ethnicity_map)\n",
    "icu_data['race'] = icu_data['race'].map(race_map)\n",
    "icu_data['ICU_stay_hrs']= (icu_data['max_out_dttm'] - icu_data['min_in_dttm']).dt.total_seconds() / 3600\n",
    "\n",
    "del location,encounter,limited,demog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = con.execute(f'''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(recorded_dttm AS datetime) AS recorded_dttm,\n",
    "        CAST(vital_value AS float) AS vital_value,\n",
    "        vital_category \n",
    "    FROM \n",
    "        {sql_import}('{vitals_filepath}')\n",
    "    WHERE \n",
    "        vital_category IN ('weight_kg', 'pulse', 'sbp', 'dbp', 'temp_c','height_inches') \n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "vitals=con.execute('''\n",
    "PIVOT vitals\n",
    "ON vital_category\n",
    "USING first(vital_value)\n",
    "GROUP BY encounter_id,recorded_dttm;\n",
    "''').df()\n",
    "\n",
    "vitals['height_meters'] = vitals['height_inches'] * 0.0254\n",
    "\n",
    "# Calculate BMI\n",
    "vitals['bmi'] = vitals['weight_kg'] / (vitals['height_meters'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,vitals, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['recorded_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['recorded_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby(['encounter_id']).agg(\n",
    "    min_bmi=('bmi', 'min'),\n",
    "    max_bmi=('bmi', 'max'),\n",
    "    avg_bmi=('bmi', 'mean'),\n",
    "    min_weight_kg=('weight_kg', 'min'),\n",
    "    max_weight_kg=('weight_kg', 'max'),\n",
    "    avg_weight_kg=('weight_kg', 'mean'),\n",
    "    min_pulse=('pulse', 'min'),\n",
    "    max_pulse=('pulse', 'max'),\n",
    "    avg_pulse=('pulse', 'mean'),\n",
    "    min_sbp=('sbp', 'min'),\n",
    "    max_sbp=('sbp', 'max'),\n",
    "    avg_sbp=('sbp', 'mean'),\n",
    "    min_dbp=('dbp', 'min'),\n",
    "    max_dbp=('dbp', 'max'),\n",
    "    avg_dbp=('dbp', 'mean'),\n",
    "    min_temp_c=('temp_c', 'min'),\n",
    "    max_temp_c=('temp_c', 'max'),\n",
    "    avg_temp_c=('temp_c', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')\n",
    "\n",
    "del vitals,icu_data_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = con.execute(f'''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(lab_order_dttm AS datetime) AS lab_order_dttm,\n",
    "        TRY_CAST(lab_value AS float) AS lab_value,\n",
    "        lab_category\n",
    "    FROM \n",
    "         {sql_import}('{labs_filepath}')\n",
    "    WHERE \n",
    "        ((lab_category='monocyte'               and lab_type_name='standard') OR\n",
    "        (lab_category='lymphocyte'              and lab_type_name='standard') OR\n",
    "        (lab_category='basophil'                and lab_type_name='standard') OR\n",
    "        (lab_category='neutrophil'              and lab_type_name='standard') OR\n",
    "        (lab_category='albumin'                 and lab_type_name='standard') OR\n",
    "        (lab_category='ast'                     and lab_type_name='standard') OR\n",
    "        (lab_category='total_protein'           and lab_type_name='standard') OR\n",
    "        (lab_category='alkaline_phosphatase'    and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_total'         and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_conjugated'    and lab_type_name='standard') OR\n",
    "        (lab_category='calcium'                 and lab_type_name='standard') OR\n",
    "        (lab_category='chloride'                and lab_type_name='standard') OR\n",
    "        (lab_category='potassium'               and lab_type_name='standard') OR\n",
    "        (lab_category='sodium'                  and lab_type_name='standard') OR\n",
    "        (lab_category='glucose_serum'           and lab_type_name='standard') OR\n",
    "        (lab_category='hemoglobin'              and lab_type_name='standard') OR\n",
    "        (lab_category='platelet count'          and lab_type_name='standard') OR\n",
    "        (lab_category='wbc'                     and lab_type_name='standard'))\n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "labs=con.execute('''\n",
    "PIVOT labs\n",
    "ON lab_category\n",
    "USING first(lab_value)\n",
    "GROUP BY encounter_id,lab_order_dttm;\n",
    "''').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data_agg=pd.merge(icu_data,labs, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['lab_order_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['lab_order_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "Lab_variables = [\n",
    "   'albumin', 'alkaline_phosphatase',\n",
    "       'ast', 'basophil', 'bilirubin_conjugated', 'bilirubin_total', 'calcium',\n",
    "       'chloride', 'hemoglobin', 'lymphocyte', 'monocyte', 'glucose_serum', \n",
    "       'neutrophil', 'potassium', 'sodium', 'total_protein','platelet count', \n",
    "       'wbc'\n",
    "]\n",
    "agg_dict = {var: ['min', 'max', 'mean'] for var in Lab_variables}\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby('encounter_id').agg(agg_dict).reset_index()\n",
    "\n",
    "icu_data_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in icu_data_agg.columns.values]\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_col=['isfemale','age', 'min_bmi', 'max_bmi', 'avg_bmi',\n",
    "       'min_weight_kg', 'max_weight_kg', 'avg_weight_kg', 'min_pulse',\n",
    "       'max_pulse', 'avg_pulse', 'min_sbp', 'max_sbp', 'avg_sbp', 'min_dbp',\n",
    "       'max_dbp', 'avg_dbp', 'min_temp_c', 'max_temp_c', 'avg_temp_c',\n",
    "       'albumin_min', 'albumin_max', 'albumin_mean',\n",
    "       'alkaline_phosphatase_min', 'alkaline_phosphatase_max',\n",
    "       'alkaline_phosphatase_mean', 'ast_min', 'ast_max', 'ast_mean',\n",
    "       'basophil_min', 'basophil_max', 'basophil_mean',\n",
    "       'bilirubin_conjugated_min', 'bilirubin_conjugated_max',\n",
    "       'bilirubin_conjugated_mean', 'bilirubin_total_min',\n",
    "       'bilirubin_total_max', 'bilirubin_total_mean', 'calcium_min',\n",
    "       'calcium_max', 'calcium_mean', 'chloride_min', 'chloride_max',\n",
    "       'chloride_mean', 'glucose_serum_min', 'glucose_serum_max',\n",
    "       'glucose_serum_mean', 'hemoglobin_min', 'hemoglobin_max',\n",
    "       'hemoglobin_mean', 'lymphocyte_min', 'lymphocyte_max',\n",
    "       'lymphocyte_mean', 'monocyte_min', 'monocyte_max', 'monocyte_mean',\n",
    "       'neutrophil_min', 'neutrophil_max', 'neutrophil_mean',\n",
    "       'platelet count_min', 'platelet count_max', 'platelet count_mean',\n",
    "       'potassium_min', 'potassium_max', 'potassium_mean', 'sodium_min',\n",
    "       'sodium_max', 'sodium_mean', 'total_protein_min', 'total_protein_max',\n",
    "       'total_protein_mean', 'wbc_min', 'wbc_max', 'wbc_mean']\n",
    "\n",
    "model=lgb.Booster(model_file=f'{root_location}/projects/Mortality_model/models/lgbm_model_20240628-092136.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features_split = [\n",
    "    \"age\",\n",
    "    \"min_pulse\",\n",
    "    \"max_pulse\",\n",
    "    \"max_temp_c\",\n",
    "    \"max_sbp\",\n",
    "    \"glucose_serum_min\",\n",
    "    \"avg_temp_c\",\n",
    "    \"sodium_max\",\n",
    "    \"min_dbp\",\n",
    "    \"platelet count_min\",\n",
    "    \"min_temp_c\",\n",
    "    \"min_sbp\",\n",
    "    \"avg_sbp\",\n",
    "    \"avg_pulse\",\n",
    "    \"wbc_min\",\n",
    "    \"glucose_serum_mean\",\n",
    "    \"alkaline_phosphatase_max\",\n",
    "    \"hemoglobin_min\",\n",
    "    \"ast_max\",\n",
    "    \"avg_dbp\"\n",
    "]\n",
    "data_unstack=icu_data[imp_features_split].unstack().reset_index(name='value').rename(columns={'level_0': 'imp_features_split', 'level_1': 'i'})\n",
    "imp_plot = generate_facetgrid_histograms(data_unstack, 'imp_features_split', 'value')\n",
    "plt.show(imp_plot)\n",
    "\n",
    "icu_data[imp_features_split].describe().reset_index().rename(columns={'index': 'statistic'}).to_csv(f'{output_directory}/imp_features_split_stats_{site_name}.csv',index=False)\n",
    "del data_unstack,imp_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data[imp_features_split].describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features_gain=['albumin_min',\n",
    " 'min_pulse',\n",
    " 'ast_mean',\n",
    " 'sodium_max',\n",
    " 'age',\n",
    " 'min_dbp',\n",
    " 'min_sbp',\n",
    " 'max_pulse',\n",
    " 'avg_temp_c',\n",
    " 'ast_max',\n",
    " 'max_temp_c',\n",
    " 'max_sbp',\n",
    " 'platelet count_min',\n",
    " 'min_temp_c',\n",
    " 'glucose_serum_min',\n",
    " 'glucose_serum_max',\n",
    " 'wbc_mean',\n",
    " 'wbc_min',\n",
    " 'albumin_mean',\n",
    " 'glucose_serum_mean']\n",
    "data_unstack=icu_data[imp_features_gain].unstack().reset_index(name='value').rename(columns={'level_0': 'imp_features_gain', 'level_1': 'i'})\n",
    "imp_plot = generate_facetgrid_histograms(data_unstack, 'imp_features_gain', 'value')\n",
    "plt.show(imp_plot)\n",
    "\n",
    "icu_data[imp_features_gain].describe().reset_index().rename(columns={'index': 'statistic'}).to_csv(f'{output_directory}/imp_features_gain_stats_{site_name}.csv',index=False)\n",
    "del data_unstack,imp_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=icu_data[model_col]\n",
    "y_test=icu_data['isdeathdispo']\n",
    "\n",
    "y_pred_proba = model.predict(X_test)\n",
    "icu_data['pred_proba'] = y_pred_proba\n",
    "\n",
    "thr=0.208\n",
    "n_bootstraps = 1000\n",
    "rng_seed = 42  \n",
    "\n",
    "def bootstrap_metric(metric_func, y_test, y_pred_proba, thr, n_bootstraps, rng_seed):\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n",
    "        if metric_func == roc_auc_score:\n",
    "            score = metric_func(y_test[indices], y_pred_proba[indices])\n",
    "        else:\n",
    "            y_pred_binary = (y_pred_proba >= thr).astype(int)\n",
    "            score = metric_func(y_test[indices], y_pred_binary[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    \n",
    "\n",
    "    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "    \n",
    "    return confidence_lower, confidence_upper\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "recall = recall_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "precision = precision_score(y_test, (y_pred_proba >= thr).astype(int))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "accuracy_ci = bootstrap_metric(accuracy_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "recall_ci = bootstrap_metric(recall_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "precision_ci = bootstrap_metric(precision_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "roc_auc_ci = bootstrap_metric(roc_auc_score, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "brier_score_ci = bootstrap_metric(brier_score_loss, y_test, y_pred_proba, thr, n_bootstraps, rng_seed)\n",
    "\n",
    "results_Metric = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'ROC AUC', 'Brier Score Loss'],\n",
    "    'Value': [accuracy, recall, precision, roc_auc, brier_score],\n",
    "    'CI Lower': [accuracy_ci[0], recall_ci[0], precision_ci[0], roc_auc_ci[0], brier_score_ci[0]],\n",
    "    'CI Upper': [accuracy_ci[1], recall_ci[1], precision_ci[1], roc_auc_ci[1], brier_score_ci[1]],\n",
    "    'SiteName': [site_name] * 5\n",
    "})\n",
    "\n",
    "results_Metric.to_csv(f'{output_directory}/result_metrics_2_{site_name}.csv', index=False)\n",
    "\n",
    "\n",
    "results_Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### probablity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df_lgbm = pd.DataFrame({'site_label ':y_test, 'site_proba': y_pred_proba,'Site_name':f\"{site_name}\" })\n",
    "#prob_df_lgbm.to_csv(f'{output_directory}/Model_probabilities_{site_name}.csv',index=False)\n",
    "prob_df_lgbm.head()\n",
    "#do not share this file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fairness test accross 'race', 'ethnicity', 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data, true_col, pred_prob_col, subgroup_cols, thr=0.208):\n",
    "    results = []\n",
    "    total_count = len(data)\n",
    "\n",
    "    for subgroup_col in subgroup_cols:\n",
    "        filtered_data = data.dropna(subset=[subgroup_col])\n",
    "        \n",
    "        for group in filtered_data[subgroup_col].unique():\n",
    "            subgroup_data = filtered_data[filtered_data[subgroup_col] == group]\n",
    "            group_count = len(subgroup_data)\n",
    "            proportion = group_count / total_count\n",
    "\n",
    "            if np.unique(subgroup_data[true_col]).size > 1:  # Check if both classes are present\n",
    "                auc = roc_auc_score(subgroup_data[true_col], subgroup_data[pred_prob_col])\n",
    "                tn, fp, fn, tp = confusion_matrix(subgroup_data[true_col], (subgroup_data[pred_prob_col] > thr).astype(int)).ravel()\n",
    "                ppv = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "                npv = tn / (tn + fn) if (tn + fn) != 0 else 0\n",
    "                recall = sensitivity\n",
    "                acc = (tp + tn) / (tp + fn + tn + fp) if (tp + fn + tn + fp) != 0 else 0\n",
    "\n",
    "                result = {\n",
    "                    'Subgroup': subgroup_col, \n",
    "                    'Group': group,\n",
    "                    'TN': tn,\n",
    "                    'TP': tp,\n",
    "                    'FP' :fp,\n",
    "                    'FN': fn,\n",
    "                    'AUC': auc, \n",
    "                    'PPV': ppv, \n",
    "                    'Sensitivity': sensitivity, \n",
    "                    'Specificity': specificity, \n",
    "                    'NPV': npv, \n",
    "                    'Recall': recall, \n",
    "                    'Accuracy': acc, \n",
    "                    'brier_score': brier_score_loss(subgroup_data[true_col], subgroup_data[pred_prob_col]),\n",
    "                    'Group Count': group_count, \n",
    "                    'Total Count': total_count, \n",
    "                    'Proportion': proportion,\n",
    "                    'site_name': f'{site_name}'\n",
    "                }\n",
    "            else:\n",
    "                result = {\n",
    "                    'Subgroup': subgroup_col, \n",
    "                    'Group': group, \n",
    "                     'TN': tn,\n",
    "                    'TP': tp,\n",
    "                    'FP' :fp,\n",
    "                    'FN': fn,\n",
    "                    'AUC': 'Not defined', \n",
    "                    'PPV': 'Not applicable', \n",
    "                    'Sensitivity': 'Not applicable', \n",
    "                    'Specificity': 'Not applicable', \n",
    "                    'NPV': 'Not applicable', \n",
    "                    'Recall': 'Not applicable', \n",
    "                    'Accuracy': 'Not applicable', \n",
    "                    'brier_score': 'Not applicable', \n",
    "                    'Group Count': group_count, \n",
    "                    'Total Count': total_count, \n",
    "                    'Proportion': proportion,\n",
    "                    'site_name': f'{site_name}'\n",
    "                }\n",
    "            \n",
    "            results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Example usage\n",
    "result_df = calculate_metrics(icu_data, 'isdeathdispo', 'pred_proba', ['race', 'ethnicity', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{output_directory}/fairness_test_{site_name}.csv',index=False)\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site Thr Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_percentile(target_var, pred_proba):\n",
    "    #thr_list = [0.99,0.97, 0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10]\n",
    "    thr_list = np.arange(1, 0, -0.01)\n",
    "    col = ['N Percentile', 'Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "    result = pd.DataFrame(columns = col)\n",
    "    i = 0\n",
    "    \n",
    "    for thr in thr_list: \n",
    "        prob = pd.DataFrame()\n",
    "        prob['target_var'] = target_var\n",
    "        prob['pred_proba'] = pred_proba\n",
    "\n",
    "        thr_value = prob['pred_proba'].quantile(thr)\n",
    "        prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr_value, 1, 0)\n",
    "        tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        ppv = tp/(tp+fp)\n",
    "        npv = tn/(tn+fn)\n",
    "        recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "        n_prec = 'Top '+ str(np.round((1 - thr) * 100,0))+ \"%\"\n",
    "        result.loc[i] = [n_prec,thr_value,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "        i+=1\n",
    "    return result\n",
    "topn=top_n_percentile(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn.to_csv(f'{output_directory}/Top_N_percentile_PPV_{site_name}.csv',index=False)\n",
    "topn.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUSH THR Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "result = pd.DataFrame(columns = col)\n",
    "\n",
    "prob = pd.DataFrame()\n",
    "prob['target_var'] = y_test\n",
    "prob['pred_proba'] = y_pred_proba\n",
    "\n",
    "prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr, 1, 0)\n",
    "tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "recall = tp/(tp+fn)\n",
    "acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "n_prec = 'Top '+ str((1 - thr))+ \"%\"\n",
    "result.loc[0] = [thr,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "\n",
    "result.to_csv(f'{output_directory}/Top_N_percentile_atRushThr_{site_name}.csv',index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "def create_calibration_data(y_test, y_pred_proba, n_bins=10):\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'y_test': y_test, 'y_pred_proba': y_pred_proba})\n",
    "    \n",
    "    # Create bins\n",
    "    df['bin'] = pd.cut(df['y_pred_proba'], bins=n_bins, labels=False, include_lowest=True)\n",
    "    \n",
    "    # Calculate mean predicted probability and actual probability in each bin\n",
    "    calibration_data = df.groupby('bin').agg(\n",
    "        predicted_prob=('y_pred_proba', 'mean'),\n",
    "        actual_prob=('y_test', 'mean'),\n",
    "        n=('y_test', 'size')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate standard error and confidence intervals\n",
    "    calibration_data['se'] = np.sqrt((calibration_data['actual_prob'] * (1 - calibration_data['actual_prob'])) / calibration_data['n'])\n",
    "    calibration_data['lower_ci'] = calibration_data['actual_prob'] - 1.96 * calibration_data['se']\n",
    "    calibration_data['upper_ci'] = calibration_data['actual_prob'] + 1.96 * calibration_data['se']\n",
    "    calibration_data['site']= site_name\n",
    "    \n",
    "    return calibration_data\n",
    "\n",
    "\n",
    "\n",
    "# Create calibration data with confidence intervals\n",
    "calibration_data = create_calibration_data(y_test, y_pred_proba)\n",
    "\n",
    "# Write the calibration data to a CSV file\n",
    "calibration_data.to_csv(f\"output/calibration_data_{site_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Smooth the line using spline interpolation\n",
    "x_new = np.linspace(calibration_data['predicted_prob'].min(), calibration_data['predicted_prob'].max(), 300)\n",
    "spl = make_interp_spline(calibration_data['predicted_prob'], calibration_data['actual_prob'], k=3)\n",
    "y_smooth = spl(x_new)\n",
    "\n",
    "\n",
    "# Plot calibration plot with shaded confidence intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(calibration_data['predicted_prob'], \n",
    "                 calibration_data['lower_ci'], \n",
    "                 calibration_data['upper_ci'], \n",
    "                 color='green', alpha=0.2, label='95% CI')\n",
    "plt.plot(x_new, y_smooth, label='Calibration', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Actual Probability')\n",
    "plt.title('Calibration Plot with Confidence Intervals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC & PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute Precision-Recall curve and AUC\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Ensure all arrays have the same length by matching dimensions correctly\n",
    "if len(fpr) != len(roc_thresholds):\n",
    "    roc_thresholds = np.append(roc_thresholds, 1)\n",
    "\n",
    "# Save values to CSV\n",
    "roc_data = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'roc_thresholds': roc_thresholds,'site':site_name})\n",
    "pr_data = pd.DataFrame({'precision': precision, 'recall': recall, 'pr_thresholds': np.append(pr_thresholds, 1),'site':site_name})\n",
    "\n",
    "roc_data.to_csv(f'output/roc_curve_data_{site_name}.csv', index=False)\n",
    "pr_data.to_csv(f'output/pr_curve_data_{site_name}.csv', index=False)\n",
    "\n",
    "# Plot ROC curve and PR curve in one image\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Plot PR curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mortality_model)",
   "language": "python",
   "name": ".mortality_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
