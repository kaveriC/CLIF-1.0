{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, auc,roc_curve,accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve,roc_auc_score,brier_score_loss\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import random\n",
    "random.seed(37)\n",
    "np.random.seed(37)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import duckdb\n",
    "# to start an in-memory database\n",
    "con = duckdb.connect(database = \":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU close to Admission\n",
    "\n",
    "1. Check ICU location_category between admission_dttmtime and 48hr stop from admission\n",
    "2. Check ICU stay at least 24 hr (for ICU - OR - ICU including OR in ICU stay 24hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_location=\"C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main\"\n",
    "\n",
    "race_map = {\n",
    "    'White': 'White',\n",
    "    'Black or African American': 'Black',\n",
    "    'Asian': 'Asian',\n",
    "    'Other': 'Others',\n",
    "    'Unknown': 'Others',\n",
    "    'Did Not Encounter': 'Others',\n",
    "    'Refusal': 'Others',\n",
    "    'American Indian or Alaska Native': 'Others',\n",
    "    'Native Hawaiian or Other Pacific Islander': 'Others',\n",
    "    np.nan: 'Others'\n",
    "}\n",
    "\n",
    "ethnicity_map = {\n",
    "    'Not Hispanic or Latino': 'Not Hispanic or Latino',\n",
    "    'Hispanic or Latino': 'Hispanic or Latino',\n",
    "    'Did Not Encounter': 'Not Hispanic or Latino',\n",
    "    'Refusal': 'Not Hispanic or Latino',\n",
    "    '*Unspecified': 'Not Hispanic or Latino',\n",
    "    np.nan: 'Not Hispanic or Latino'\n",
    "}\n",
    "\n",
    "site_name='RUSH'\n",
    "\n",
    "no_show=['encounter_id', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd.read_csv(\"C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_adt.csv\")\n",
    "encounter = pd.read_csv(\"C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_encounter_demographics_dispo_clean.csv\")\n",
    "limited=pd.read_csv(\"C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_limited_identifiers.csv\")\n",
    "demog=pd.read_csv(\"C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_patient_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join=pd.merge(location[['encounter_id','location_category','in_dttm','out_dttm']],\\\n",
    "              limited[['encounter_id','admission_dttm']], on=['encounter_id'], how='left')\n",
    "\n",
    "icu_data=pd.merge(join,\\\n",
    "                  encounter[['encounter_id','age_at_admission','disposition']], on=['encounter_id'], how='left')\n",
    "\n",
    "icu_data['in_dttm'] = pd.to_datetime(icu_data['in_dttm'])\n",
    "icu_data['admission_dttm'] = pd.to_datetime(icu_data['admission_dttm'])\n",
    "icu_data['out_dttm'] = pd.to_datetime(icu_data['out_dttm'])\n",
    "#icu_data['age_at_admission'] = icu_data['age_at_admission'].astype(int)\n",
    "\n",
    "icu_48hr_check = icu_data[\n",
    "    (icu_data['location_category'] == 'ICU') &\n",
    "    (icu_data['in_dttm'] >= icu_data['admission_dttm']) &\n",
    "    (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=48)) & \n",
    "    (icu_data['age_at_admission'] >= 18) & (icu_data['age_at_admission'].notna())  \n",
    "]['encounter_id'].unique()\n",
    "\n",
    "icu_data=icu_data[icu_data['encounter_id'].isin(icu_48hr_check) & (icu_data['in_dttm'] <= icu_data['admission_dttm'] + pd.Timedelta(hours=72))].reset_index(drop=True)\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm']).reset_index(drop=True)\n",
    "\n",
    "icu_data[\"RANK\"]=icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(\"encounter_id\")[\"in_dttm\"].rank(method=\"first\", ascending=True).astype(int)\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['RANK'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "icu_data=icu_data[icu_data['RANK']>=icu_data['min_icu']].reset_index(drop=True)\n",
    "\n",
    "icu_data.loc[icu_data['location_category'] == 'OR', 'location_category'] = 'ICU'\n",
    "\n",
    "icu_data['group_id'] = (icu_data.groupby('encounter_id')['location_category'].shift() != icu_data['location_category']).astype(int)\n",
    "icu_data['group_id'] = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby('encounter_id')['group_id'].cumsum()\n",
    "\n",
    "icu_data = icu_data.sort_values(by=['in_dttm'], ascending=True).groupby(['encounter_id', 'location_category', 'group_id']).agg(\n",
    "    min_in_dttm=('in_dttm', 'min'),\n",
    "    max_out_dttm=('out_dttm', 'max'),\n",
    "    admission_dttm=('admission_dttm', 'first'),\n",
    "    age=('age_at_admission', 'first'),\n",
    "    dispo=('disposition', 'first')\n",
    ").reset_index()\n",
    "\n",
    "min_icu=icu_data[icu_data['location_category'] == 'ICU'].groupby('encounter_id')['group_id'].min()\n",
    "icu_data=pd.merge(icu_data, pd.DataFrame(zip(min_icu.index, min_icu.values), columns=['encounter_id', 'min_icu']), on='encounter_id', how='left')\n",
    "\n",
    "icu_data=icu_data[(icu_data['min_icu']==icu_data['group_id']) &\n",
    "         (icu_data['max_out_dttm']-icu_data['min_in_dttm'] >= pd.Timedelta(hours=24))\n",
    "         ].reset_index(drop=True)\n",
    "\n",
    "icu_data['after_24hr']=icu_data['min_in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "icu_data=icu_data[['encounter_id','min_in_dttm','max_out_dttm','admission_dttm','after_24hr','age','dispo']]\n",
    "\n",
    "icu_data=pd.merge(icu_data,\\\n",
    "                  demog, on=['encounter_id'], how='left')[['encounter_id','min_in_dttm','after_24hr','admission_dttm','max_out_dttm','age','dispo','sex','ethnicity','race']]\n",
    "icu_data=icu_data[~icu_data['sex'].isna()].reset_index(drop=True)\n",
    "icu_data['isfemale']=(icu_data['sex'].str.lower() == 'female').astype(int)\n",
    "icu_data['isdeathdispo'] = (icu_data['dispo'].str.contains('dead|expired', case=False, regex=True)).astype(int)\n",
    "\n",
    "icu_data['ethnicity'] = icu_data['ethnicity'].map(ethnicity_map)\n",
    "icu_data['race'] = icu_data['race'].map(race_map)\n",
    "icu_data['ICU_stay_hrs']= (icu_data['max_out_dttm'] - icu_data['min_in_dttm']).dt.total_seconds() / 3600\n",
    "\n",
    "del location,encounter,limited,demog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = con.execute('''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(recorded_dttm AS datetime) AS recorded_dttm,\n",
    "        CAST(vital_value AS float) AS vital_value,\n",
    "        vital_category  \n",
    "    FROM \n",
    "        read_csv_auto('C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_vitals_clean.csv')\n",
    "    WHERE \n",
    "        vital_category  IN ('weight_kg', 'pulse', 'sbp', 'dbp', 'temp_c','height_inches') \n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "vitals=con.execute('''\n",
    "PIVOT vitals\n",
    "ON vital_category \n",
    "USING first(vital_value)\n",
    "GROUP BY encounter_id,recorded_dttm;\n",
    "''').df()\n",
    "\n",
    "vitals['height_meters'] = vitals['height_inches'] * 0.0254\n",
    "vitals['bmi'] = vitals['weight_kg'] / (vitals['height_meters'] ** 2)\n",
    "\n",
    "\n",
    "icu_data_agg=pd.merge(icu_data,vitals, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['recorded_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['recorded_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby(['encounter_id']).agg(\n",
    "    min_bmi=('bmi', 'min'),\n",
    "    max_bmi=('bmi', 'max'),\n",
    "    avg_bmi=('bmi', 'mean'),\n",
    "    min_weight_kg=('weight_kg', 'min'),\n",
    "    max_weight_kg=('weight_kg', 'max'),\n",
    "    avg_weight_kg=('weight_kg', 'mean'),\n",
    "    min_pulse=('pulse', 'min'),\n",
    "    max_pulse=('pulse', 'max'),\n",
    "    avg_pulse=('pulse', 'mean'),\n",
    "    min_sbp=('sbp', 'min'),\n",
    "    max_sbp=('sbp', 'max'),\n",
    "    avg_sbp=('sbp', 'mean'),\n",
    "    min_dbp=('dbp', 'min'),\n",
    "    max_dbp=('dbp', 'max'),\n",
    "    avg_dbp=('dbp', 'mean'),\n",
    "    min_temp_c=('temp_c', 'min'),\n",
    "    max_temp_c=('temp_c', 'max'),\n",
    "    avg_temp_c=('temp_c', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')\n",
    "\n",
    "del vitals,icu_data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data.drop(columns=no_show).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = con.execute('''\n",
    "    SELECT \n",
    "        encounter_id,\n",
    "        CAST(lab_order_dttm AS datetime) AS lab_order_dttm,\n",
    "        TRY_CAST(lab_value AS float) AS lab_value,\n",
    "        lab_category \n",
    "    FROM \n",
    "        read_csv_auto('C:/Users/vchaudha/OneDrive - rush.edu/CLIF-1.0-main/rclif/clif_labs_clean.csv')\n",
    "    WHERE \n",
    "        ((lab_category='monocyte' and reference_unit = '%' and lab_type_name='standard') OR\n",
    "        (lab_category='lymphocyte' and reference_unit = '%' and lab_type_name='standard') OR\n",
    "        (lab_category='basophil' and reference_unit = '%' and lab_type_name='standard') OR\n",
    "        (lab_category='neutrophil' and reference_unit = '%' and lab_type_name='standard') OR\n",
    "        (lab_category='albumin' and reference_unit = 'g/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='ast' and reference_unit = 'U/L' and lab_type_name='standard') OR\n",
    "        (lab_category='total_protein' and reference_unit = 'g/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='alkaline_phosphatase' and reference_unit = 'U/L' and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_total' and reference_unit = 'mg/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='bilirubin_conjugated' and reference_unit = 'mg/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='calcium' and reference_unit = 'mg/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='chloride' and reference_unit = 'mmol/L' and lab_type_name='standard') OR\n",
    "        (lab_category='potassium' and reference_unit = 'mmol/L' and lab_type_name='standard') OR\n",
    "        (lab_category='sodium' and reference_unit = 'mmol/L' and lab_type_name='standard') OR\n",
    "        (lab_category='glucose_serum' and reference_unit = 'mg/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='hemoglobin' and reference_unit = 'g/dL' and lab_type_name='standard') OR\n",
    "        (lab_category='platelet count' and reference_unit = 'K/uL' and lab_type_name='standard') OR\n",
    "        (lab_category='wbc' and reference_unit = 'K/uL' and lab_type_name='standard'))  \n",
    "        AND encounter_id IN (SELECT DISTINCT encounter_id FROM icu_data);\n",
    "''').df()\n",
    "\n",
    "labs=con.execute('''\n",
    "PIVOT labs\n",
    "ON lab_category\n",
    "USING first(lab_value)\n",
    "GROUP BY encounter_id,lab_order_dttm;\n",
    "''').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "icu_data_agg=pd.merge(icu_data,labs, on=['encounter_id'], how='left')\n",
    "icu_data_agg=icu_data_agg[(icu_data_agg['lab_order_dttm'] >= icu_data_agg['min_in_dttm']) & (icu_data_agg['lab_order_dttm'] <= icu_data_agg['after_24hr'])].reset_index(drop=True)\n",
    "\n",
    "Lab_variables = [\n",
    "   'albumin', 'alkaline_phosphatase',\n",
    "       'ast', 'basophil', 'bilirubin_conjugated', 'bilirubin_total', 'calcium',\n",
    "       'chloride', 'glucose_serum', 'hemoglobin', 'lymphocyte', 'monocyte',\n",
    "       'neutrophil', 'platelet count', 'potassium', 'sodium', 'total_protein',\n",
    "       'wbc'\n",
    "]\n",
    "agg_dict = {var: ['min', 'max', 'mean'] for var in Lab_variables}\n",
    "\n",
    "icu_data_agg = icu_data_agg.groupby('encounter_id').agg(agg_dict).reset_index()\n",
    "\n",
    "icu_data_agg.columns = ['_'.join(col).strip() if col[1] else col[0] for col in icu_data_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_data=pd.merge(icu_data,icu_data_agg, on=['encounter_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = icu_data[icu_data['admission_dttm'].dt.year.isin([2020, 2021])]\n",
    "train_data = icu_data[~icu_data['admission_dttm'].dt.year.isin([2020, 2021])]\n",
    "\n",
    "#train_data, test_data = train_test_split(icu_data, test_size=0.2, random_state=42)\n",
    "# cutoff_date = icu_data['admission_dttm'].quantile(0.7)\n",
    "# print(cutoff_date)\n",
    "# train_data = icu_data[icu_data['admission_dttm'] <= cutoff_date]\n",
    "# test_data = icu_data[icu_data['admission_dttm'] > cutoff_date]\n",
    "\n",
    "model_col=['isfemale','age', 'min_bmi', 'max_bmi', 'avg_bmi',\n",
    "       'min_weight_kg', 'max_weight_kg', 'avg_weight_kg', 'min_pulse',\n",
    "       'max_pulse', 'avg_pulse', 'min_sbp', 'max_sbp', 'avg_sbp', 'min_dbp',\n",
    "       'max_dbp', 'avg_dbp', 'min_temp_c', 'max_temp_c', 'avg_temp_c',\n",
    "       'albumin_min', 'albumin_max', 'albumin_mean',\n",
    "       'alkaline_phosphatase_min', 'alkaline_phosphatase_max',\n",
    "       'alkaline_phosphatase_mean', 'ast_min', 'ast_max', 'ast_mean',\n",
    "       'basophil_min', 'basophil_max', 'basophil_mean',\n",
    "       'bilirubin_conjugated_min', 'bilirubin_conjugated_max',\n",
    "       'bilirubin_conjugated_mean', 'bilirubin_total_min',\n",
    "       'bilirubin_total_max', 'bilirubin_total_mean', 'calcium_min',\n",
    "       'calcium_max', 'calcium_mean', 'chloride_min', 'chloride_max',\n",
    "       'chloride_mean', 'glucose_serum_min', 'glucose_serum_max',\n",
    "       'glucose_serum_mean', 'hemoglobin_min', 'hemoglobin_max',\n",
    "       'hemoglobin_mean', 'lymphocyte_min', 'lymphocyte_max',\n",
    "       'lymphocyte_mean', 'monocyte_min', 'monocyte_max', 'monocyte_mean',\n",
    "       'neutrophil_min', 'neutrophil_max', 'neutrophil_mean',\n",
    "       'platelet count_min', 'platelet count_max', 'platelet count_mean',\n",
    "       'potassium_min', 'potassium_max', 'potassium_mean', 'sodium_min',\n",
    "       'sodium_max', 'sodium_mean', 'total_protein_min', 'total_protein_max',\n",
    "       'total_protein_mean', 'wbc_min', 'wbc_max', 'wbc_mean']\n",
    "\n",
    "X_train=train_data[model_col]\n",
    "y_train=train_data['isdeathdispo']\n",
    "\n",
    "#test\n",
    "X_test=test_data[model_col]\n",
    "y_test=test_data['isdeathdispo']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export:\n",
    "    train_data['Data_Type'] = 'train'\n",
    "    test_data['Data_Type'] = 'test'\n",
    "\n",
    "    # Concatenating the training and testing data into one DataFrame\n",
    "    combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "    combined_data.to_csv('train_test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    metric='binary_logloss',\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=10,\n",
    "    n_estimators=50,\n",
    "    feature_fraction= 1.0,\n",
    "    device='gpu'  # Enable GPU acceleration\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics at default threshold (0.5)\n",
    "default_threshold = 0.5\n",
    "y_pred_default = (y_pred_proba >= default_threshold).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_default)\n",
    "recall = recall_score(y_test, y_pred_default)\n",
    "precision = precision_score(y_test, y_pred_default)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "print(f'brier_score : {brier_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot ROC curve on the first subplot\n",
    "ax1.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "ax1.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('Receiver Operating Characteristic')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "# Calculate accuracy, recall, and precision at different thresholds for the second subplot\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_threshold))\n",
    "    recalls.append(recall_score(y_test, y_pred_threshold))\n",
    "    precisions.append(precision_score(y_test, y_pred_threshold))\n",
    "\n",
    "# Plot accuracy, recall, and precision at different thresholds on the second subplot\n",
    "ax2.plot(thresholds, accuracies, label='Accuracy')\n",
    "ax2.plot(thresholds, recalls, label='Recall')\n",
    "ax2.plot(thresholds, precisions, label='Precision')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.set_xlabel('Threshold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Accuracy, Recall, and Precision at Different Thresholds')\n",
    "ax2.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "lgb.plot_importance(model, max_num_features=20, importance_type='split')\n",
    "plt.title(\"Feature Importance (Split)\")\n",
    "plt.show()\n",
    "\n",
    "lgb.plot_importance(model, max_num_features=20, importance_type='gain')\n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "plt.show()\n",
    "\n",
    "# creating a dataframe of target and probabilities\n",
    "prob_df_lgbm = pd.DataFrame({'y':y_test, 'y_hat': y_pred_proba})\n",
    "\n",
    "# binning the dataframe, so we can see success rates for bins of probability\n",
    "bins = np.arange(0.05, 1.00, 0.05)\n",
    "prob_df_lgbm.loc[:,'prob_bin'] = np.digitize(prob_df_lgbm['y_hat'], bins)\n",
    "prob_df_lgbm.loc[:,'prob_bin_val'] = prob_df_lgbm['prob_bin'].replace(dict(zip(range(len(bins)), bins)))\n",
    "\n",
    "# opening figure\n",
    "plt.figure(figsize=(6,5), dpi=150)\n",
    "\n",
    "# plotting ideal line\n",
    "plt.plot([0,1],[0,1], 'k--', label='ideal')\n",
    "\n",
    "# plotting calibration for lgbm\n",
    "calibration_y = prob_df_lgbm.groupby('prob_bin_val')['y'].mean()\n",
    "calibration_x = prob_df_lgbm.groupby('prob_bin_val')['y_hat'].mean()\n",
    "plt.plot(calibration_x, calibration_y, marker='o', label='lgbm')\n",
    "\n",
    "# legend and titles\n",
    "plt.title('Calibration plot for LGBM')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Actual fraction of positives')\n",
    "plt.legend()\n",
    "\n",
    "def top_n_percentile(target_var, pred_proba):\n",
    "    #thr_list = [0.99,0.97, 0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10]\n",
    "    thr_list = np.arange(1, 0, -0.01)\n",
    "    col = ['N Percentile', 'Thr Value','TN','FP','FN','TP','Sensitivity','Specificity','PPV', 'NPV' ,'Recall','Accuracy','site_name']\n",
    "    result = pd.DataFrame(columns = col)\n",
    "    i = 0\n",
    "    \n",
    "    for thr in thr_list: \n",
    "        prob = pd.DataFrame()\n",
    "        prob['target_var'] = target_var\n",
    "        prob['pred_proba'] = pred_proba\n",
    "\n",
    "        thr_value = prob['pred_proba'].quantile(thr)\n",
    "        prob['pred_proba_bin'] = np.where(prob['pred_proba'] >= thr_value, 1, 0)\n",
    "        tn,fp,fn,tp = confusion_matrix(prob['target_var'], prob['pred_proba_bin']).ravel()\n",
    "\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        ppv = tp/(tp+fp)\n",
    "        npv = tn/(tn+fn)\n",
    "        recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+fn+tn+fp)\n",
    "        n_prec = 'Top '+ str(np.round((1 - thr) * 100,0))+ \"%\"\n",
    "        result.loc[i] = [n_prec,thr_value,tn,fp,fn,tp,sensitivity,specificity ,ppv,npv, recall, acc,f'{site_name}']\n",
    "        i+=1\n",
    "    return result\n",
    "topn=top_n_percentile(y_test,y_pred_proba)\n",
    "#topn.to_csv(f'Top_N_percentile_PPV_{site_name}.csv',index=False)\n",
    "\n",
    "if export:\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_filename = f\"models/lgbm_model_{timestamp}.txt\"\n",
    "    model_filename_pkl = f\"models/lgbm_model_{timestamp}.pkl\"\n",
    "\n",
    "    with open(model_filename_pkl, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    model.booster_.save_model(model_filename)\n",
    "\n",
    "    log_entry = f\"Test AUC: {roc_auc}, Model: {model_filename}\\n\"\n",
    "\n",
    "    with open(\"models/model_log.txt\", \"a\") as log_file:\n",
    "        log_file.write(log_entry)\n",
    "\n",
    "    print(f\"Model saved as {model_filename} and log updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search sample code\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, brier_score_loss\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'num_leaves': [31, 50, 100],\n",
    "#     'max_depth': [-1, 10, 20],\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'feature_fraction': [0.8, 0.9, 1.0]\n",
    "# }\n",
    "\n",
    "# # Initialize the model\n",
    "# model = LGBMClassifier(\n",
    "#     boosting_type='gbdt',\n",
    "#     objective='binary',\n",
    "#     metric='binary_logloss',\n",
    "#     device='gpu'  # Enable GPU acceleration\n",
    "# )\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='roc_auc', verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Collect results\n",
    "# results = []\n",
    "# for params, mean_score, scores in zip(grid_search.cv_results_['params'],\n",
    "#                                       grid_search.cv_results_['mean_test_score'],\n",
    "#                                       grid_search.cv_results_['std_test_score']):\n",
    "#     print(f\"Params: {params}, Mean ROC AUC: {mean_score:.4f}, Std: {scores:.4f}\")\n",
    "#     model.set_params(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "#     y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
    "#     accuracy = accuracy_score(y_test, y_pred_default)\n",
    "#     recall = recall_score(y_test, y_pred_default)\n",
    "#     precision = precision_score(y_test, y_pred_default)\n",
    "#     roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "#     brier_score = brier_score_loss(y_test, y_pred_proba)\n",
    "#     results.append({\n",
    "#         'params': params,\n",
    "#         'accuracy': accuracy,\n",
    "#         'recall': recall,\n",
    "#         'precision': precision,\n",
    "#         'roc_auc': roc_auc,\n",
    "#         'brier_score': brier_score\n",
    "#     })\n",
    "\n",
    "# # Convert results to DataFrame and save to CSV\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('grid_search_results.csv', index=False)\n",
    "# print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mortality_model)",
   "language": "python",
   "name": ".mortality_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
